# This generic configuration which uses the python script evaluation.py as it's LLM.
# Prompts are taken from the specified text files.
# Tests are taken from tests.csv
# Instructions in the readme.
# Learn more: https://promptfoo.dev/docs/configuration/guide
description: 'Check quotes in chunk'

prompts:
  - file://prompt_with_context.txt

providers:
  - id: 'python:evaluation.py'
    label: 'Python Gemini Script'   # Optional display label for this provider
    # config:
    #   pythonExecutable: *can set the python executable if you want, but I've just been making sure I'm in the right venv.*

tests: tests_quote_in_chunk.csv